{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30f4dcf8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ed385ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3cb052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataframe path\n",
    "df_path = \"../data/final_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f59021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data :            author                                        description  \\\n",
      "0          TuaAnon  yes, it's an lte watch with data turned on, no...   \n",
      "1  DemandScary1934  how accurate is the active/total calorie track...   \n",
      "2         Vinumite  fell very hard blackout drunk and lost watch. ...   \n",
      "3          Damarou  pls tell me iâ€˜m not the only one who has such ...   \n",
      "4       ThorNike13  deleted apps in watch app on iphone with weird...   \n",
      "\n",
      "    subreddit  des_word_count  \n",
      "0  AppleWatch              48  \n",
      "1  AppleWatch              10  \n",
      "2  AppleWatch              59  \n",
      "3  AppleWatch              15  \n",
      "4  AppleWatch              15  \n",
      "\n",
      "--------------------------\n",
      "\n",
      " Columns : ['author', 'description', 'subreddit', 'des_word_count']\n",
      "\n",
      "--------------------------\n",
      "\n",
      " Size of the dataset : 5270\n",
      "\n",
      "--------------------------\n",
      "\n",
      " Total number of columns : 4\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv(df_path).drop(columns=\"Unnamed: 0\")\n",
    "\n",
    "# Get some basic information \n",
    "print(f\"Sample Data :{df.head()}\")\n",
    "print(f\"\\n--------------------------\\n\\n Columns : {[i for i in df.columns]}\")\n",
    "print(f\"\\n--------------------------\\n\\n Size of the dataset : {df.shape[0]}\")\n",
    "print(f\"\\n--------------------------\\n\\n Total number of columns : {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020cf07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unusefull columns\n",
    "df.drop(columns =[\"author\", \"des_word_count\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94163811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label column (target column)\n",
    "df[\"subreddit\"] = df[\"subreddit\"].map({\"GalaxyWatch\": 1, \"AppleWatch\":0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d97aa63",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "230865c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cite: Got help form Katie Sylvia\n",
    "# a function for stemming\n",
    "def stem_words(text):\n",
    "    # Initialize the Porter stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    # Tokenize the text into individual words\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Stem each word and join them back into a string\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    stemmed_text = \" \".join(stemmed_words)\n",
    "    \n",
    "    return stemmed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d23ca963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search over with pipeline estimator\n",
    "def gridsearching(estimator, param_grid, model_name, transformer_name):\n",
    "    \n",
    "    print(f\" Summary of {model_name} Model with {transformer_name} Transformer Evaluation \".center(115, \"=\"))\n",
    "    \n",
    "    # Instantiate a GridSearch model\n",
    "    gs = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=5, n_jobs=5)\n",
    "\n",
    "    # Fit the model to traning data\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # Get to know wich params were the best ones\n",
    "    print(\" The Best Params \".center(34, \"=\"))\n",
    "    print(gs.best_params_)\n",
    "    print()\n",
    "\n",
    "    # Get to know the best score\n",
    "    print(\" The Best Score \".center(34, \"=\"))\n",
    "    print(gs.best_score_)\n",
    "    print()\n",
    "\n",
    "    # Train data score\n",
    "    print(\" Train Score \".center(34, \"=\"))\n",
    "    print(gs.score(X_train, y_train))\n",
    "    print()\n",
    "\n",
    "    # Test data score\n",
    "    print(\" Test Score \".center(34, \"=\"))\n",
    "    print(gs.score(X_test, y_test))\n",
    "    \n",
    "    # Get predictions\n",
    "    preds = gs.predict(X_test)\n",
    "\n",
    "    # Confusion matrix values\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "    # Confusion matrix\n",
    "    plot_confusion_matrix(gs, X_test, y_test, cmap=\"Purples\", values_format=\"d\")\n",
    "\n",
    "    plt.title(f\"The Confusion Matrix of {model_name} with {transformer_name}\");\n",
    "\n",
    "    # Evaluate a model\n",
    "    print(f\" Evaluation Metrics \".center(34, \"=\"))\n",
    "    print(f\"Accuracy  ---------- {accuracy_score(y_test, preds)}\")\n",
    "    print(f\"Precision  --------- {precision_score(y_test, preds)}\")\n",
    "    print(f\"Sensitivity  ------- {recall_score(y_test, preds)}\")\n",
    "    print(f\"Specifity  --------- {tn/(tn + fp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3d6410",
   "metadata": {},
   "source": [
    "## Baselin Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e62cae5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape ---------- (5270,)\n",
      "y shape ---------- (5270,)\n"
     ]
    }
   ],
   "source": [
    "# Define X (features) and y(target)\n",
    "X = df[\"description\"]\n",
    "y = df[\"subreddit\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "print(f\"X shape ---------- {X.shape}\")\n",
    "print(f\"y shape ---------- {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8f989e",
   "metadata": {},
   "source": [
    "### Baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13a2120c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.534143\n",
       "1    0.465857\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the ratio of classes\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe4562b",
   "metadata": {},
   "source": [
    "**Baseline accuracy score is 0.53 which is the majority class**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3a10b7",
   "metadata": {},
   "source": [
    "## AdaBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8297922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a high biased Decision Tree\n",
    "tree = DecisionTreeClassifier(max_depth=1, random_state=111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca29a208",
   "metadata": {},
   "source": [
    "### AdaBoost with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8004084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the pipeline with Logistic Regression and CountVectorizer transformer\n",
    "pipe = Pipeline([\n",
    "    (\"cvec\", CountVectorizer()),\n",
    "    (\"ada\", AdaBoostClassifier(base_estimator=tree, algorithm='SAMME.R'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdf73718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('cvec', CountVectorizer()),\n",
       "  ('ada',\n",
       "   AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1,\n",
       "                                                            random_state=111)))],\n",
       " 'verbose': False,\n",
       " 'cvec': CountVectorizer(),\n",
       " 'ada': AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1,\n",
       "                                                          random_state=111)),\n",
       " 'cvec__analyzer': 'word',\n",
       " 'cvec__binary': False,\n",
       " 'cvec__decode_error': 'strict',\n",
       " 'cvec__dtype': numpy.int64,\n",
       " 'cvec__encoding': 'utf-8',\n",
       " 'cvec__input': 'content',\n",
       " 'cvec__lowercase': True,\n",
       " 'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__preprocessor': None,\n",
       " 'cvec__stop_words': None,\n",
       " 'cvec__strip_accents': None,\n",
       " 'cvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'cvec__tokenizer': None,\n",
       " 'cvec__vocabulary': None,\n",
       " 'ada__algorithm': 'SAMME.R',\n",
       " 'ada__base_estimator__ccp_alpha': 0.0,\n",
       " 'ada__base_estimator__class_weight': None,\n",
       " 'ada__base_estimator__criterion': 'gini',\n",
       " 'ada__base_estimator__max_depth': 1,\n",
       " 'ada__base_estimator__max_features': None,\n",
       " 'ada__base_estimator__max_leaf_nodes': None,\n",
       " 'ada__base_estimator__min_impurity_decrease': 0.0,\n",
       " 'ada__base_estimator__min_samples_leaf': 1,\n",
       " 'ada__base_estimator__min_samples_split': 2,\n",
       " 'ada__base_estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'ada__base_estimator__random_state': 111,\n",
       " 'ada__base_estimator__splitter': 'best',\n",
       " 'ada__base_estimator': DecisionTreeClassifier(max_depth=1, random_state=111),\n",
       " 'ada__learning_rate': 1.0,\n",
       " 'ada__n_estimators': 50,\n",
       " 'ada__random_state': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get pipeline params\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146d425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pipeline params by cvec\n",
    "pipe_params = {\n",
    "    \"cvec__tokenizer\": [None, stem_words],\n",
    "    \"cvec__max_features\": [5_000, 10_000, 20_000, 30_000],\n",
    "    \"cvec__min_df\": [2, 3],\n",
    "    \"cvec__max_df\": [.9, .95],\n",
    "    \"cvec__stop_words\": [None, \"english\"],\n",
    "    \"cvec__ngram_range\": [(1, 1), (1, 2)],\n",
    "    \"ada__learning_rate\": [0.1, 1, 10]\n",
    "    \"ada__n_estimators\": [100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03995570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the result of the model with defined parameters in GreadSearch\n",
    "gridsearching(estimator=pipe, param_grid=pipe_params, model_name=\"AdaBoost\", transformer_name=\"CountVectorizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed59e32",
   "metadata": {},
   "source": [
    "### AdaBoost with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6eca157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the pipeline with Logistic Regression and CountVectorizer transformer\n",
    "pipe = Pipeline([\n",
    "    (\"tvec\", TfidfVectorizer()),\n",
    "    (\"ada\", AdaBoostClassifier(base_estimator=tree, algorithm='SAMME.R'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98dbbbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('tvec', TfidfVectorizer()),\n",
       "  ('ada',\n",
       "   AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1,\n",
       "                                                            random_state=111)))],\n",
       " 'verbose': False,\n",
       " 'tvec': TfidfVectorizer(),\n",
       " 'ada': AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1,\n",
       "                                                          random_state=111)),\n",
       " 'tvec__analyzer': 'word',\n",
       " 'tvec__binary': False,\n",
       " 'tvec__decode_error': 'strict',\n",
       " 'tvec__dtype': numpy.float64,\n",
       " 'tvec__encoding': 'utf-8',\n",
       " 'tvec__input': 'content',\n",
       " 'tvec__lowercase': True,\n",
       " 'tvec__max_df': 1.0,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 1,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__norm': 'l2',\n",
       " 'tvec__preprocessor': None,\n",
       " 'tvec__smooth_idf': True,\n",
       " 'tvec__stop_words': None,\n",
       " 'tvec__strip_accents': None,\n",
       " 'tvec__sublinear_tf': False,\n",
       " 'tvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tvec__tokenizer': None,\n",
       " 'tvec__use_idf': True,\n",
       " 'tvec__vocabulary': None,\n",
       " 'ada__algorithm': 'SAMME.R',\n",
       " 'ada__base_estimator__ccp_alpha': 0.0,\n",
       " 'ada__base_estimator__class_weight': None,\n",
       " 'ada__base_estimator__criterion': 'gini',\n",
       " 'ada__base_estimator__max_depth': 1,\n",
       " 'ada__base_estimator__max_features': None,\n",
       " 'ada__base_estimator__max_leaf_nodes': None,\n",
       " 'ada__base_estimator__min_impurity_decrease': 0.0,\n",
       " 'ada__base_estimator__min_samples_leaf': 1,\n",
       " 'ada__base_estimator__min_samples_split': 2,\n",
       " 'ada__base_estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'ada__base_estimator__random_state': 111,\n",
       " 'ada__base_estimator__splitter': 'best',\n",
       " 'ada__base_estimator': DecisionTreeClassifier(max_depth=1, random_state=111),\n",
       " 'ada__learning_rate': 1.0,\n",
       " 'ada__n_estimators': 50,\n",
       " 'ada__random_state': None}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get pipeline params\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a3342b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pipeline params by cvec\n",
    "pipe_params = {\n",
    "    \"tvec__tokenizer\": [None, stem_words],\n",
    "    \"tvec__max_features\": [5_000, 10_000, 20_000, 30_000],\n",
    "    \"tvec__min_df\": [2, 3],\n",
    "    \"tvec__max_df\": [.9, .95],\n",
    "    \"tvec__stop_words\": [None, \"english\"],\n",
    "    \"tvec__ngram_range\": [(1, 1), (1, 2)],\n",
    "    \"ada__learning_rate\": [0.1, 1, 10],\n",
    "    \"ada__n_estimators\": [100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e21868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the result of the model with defined parameters in GreadSearch\n",
    "gridsearching(estimator=pipe, param_grid=pipe_params, model_name=\"AdaBoost\", transformer_name=\"TfidfVectorizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e5b6d6",
   "metadata": {},
   "source": [
    "### GradientBoost with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d38448fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the pipeline with Logistic Regression and CountVectorizer transformer\n",
    "pipe = Pipeline([\n",
    "    (\"cvec\", CountVectorizer()),\n",
    "    (\"gb\", GradientBoostingClassifier(random_state=111))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e08a76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('cvec', CountVectorizer()),\n",
       "  ('gb', GradientBoostingClassifier(random_state=111))],\n",
       " 'verbose': False,\n",
       " 'cvec': CountVectorizer(),\n",
       " 'gb': GradientBoostingClassifier(random_state=111),\n",
       " 'cvec__analyzer': 'word',\n",
       " 'cvec__binary': False,\n",
       " 'cvec__decode_error': 'strict',\n",
       " 'cvec__dtype': numpy.int64,\n",
       " 'cvec__encoding': 'utf-8',\n",
       " 'cvec__input': 'content',\n",
       " 'cvec__lowercase': True,\n",
       " 'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': None,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__preprocessor': None,\n",
       " 'cvec__stop_words': None,\n",
       " 'cvec__strip_accents': None,\n",
       " 'cvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'cvec__tokenizer': None,\n",
       " 'cvec__vocabulary': None,\n",
       " 'gb__ccp_alpha': 0.0,\n",
       " 'gb__criterion': 'friedman_mse',\n",
       " 'gb__init': None,\n",
       " 'gb__learning_rate': 0.1,\n",
       " 'gb__loss': 'deviance',\n",
       " 'gb__max_depth': 3,\n",
       " 'gb__max_features': None,\n",
       " 'gb__max_leaf_nodes': None,\n",
       " 'gb__min_impurity_decrease': 0.0,\n",
       " 'gb__min_samples_leaf': 1,\n",
       " 'gb__min_samples_split': 2,\n",
       " 'gb__min_weight_fraction_leaf': 0.0,\n",
       " 'gb__n_estimators': 100,\n",
       " 'gb__n_iter_no_change': None,\n",
       " 'gb__random_state': 111,\n",
       " 'gb__subsample': 1.0,\n",
       " 'gb__tol': 0.0001,\n",
       " 'gb__validation_fraction': 0.1,\n",
       " 'gb__verbose': 0,\n",
       " 'gb__warm_start': False}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get pipeline params\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da69011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pipeline params by cvec\n",
    "pipe_params = {\n",
    "    \"cvec__tokenizer\": [None, stem_words],\n",
    "    \"cvec__max_features\": [5_000, 10_000, 20_000, 30_000],\n",
    "    \"cvec__min_df\": [2, 3],\n",
    "    \"cvec__max_df\": [.9, .95],\n",
    "    \"cvec__stop_words\": [None, \"english\"],\n",
    "    \"tvec__ngram_range\": [(1, 1), (1, 2)],\n",
    "    \"gb__learning_rate\": [0.1, 1, 10],\n",
    "    \"gb__max_depth\": [None, 1, 2, 3, 4],\n",
    "    \"gb__n_estimators\": [100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bd09b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the result of the model with defined parameters in GreadSearch\n",
    "gridsearching(estimator=pipe, param_grid=pipe_params, model_name=\"GradientBoost\", transformer_name=\"CountVectorizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d40b02",
   "metadata": {},
   "source": [
    "### GradientBoost with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f5e85a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the pipeline with Logistic Regression and CountVectorizer transformer\n",
    "pipe = Pipeline([\n",
    "    (\"tvec\", TfidfVectorizer()),\n",
    "    (\"gb\", GradientBoostingClassifier(random_state=111))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10993a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('tvec', TfidfVectorizer()),\n",
       "  ('gb', GradientBoostingClassifier(random_state=111))],\n",
       " 'verbose': False,\n",
       " 'tvec': TfidfVectorizer(),\n",
       " 'gb': GradientBoostingClassifier(random_state=111),\n",
       " 'tvec__analyzer': 'word',\n",
       " 'tvec__binary': False,\n",
       " 'tvec__decode_error': 'strict',\n",
       " 'tvec__dtype': numpy.float64,\n",
       " 'tvec__encoding': 'utf-8',\n",
       " 'tvec__input': 'content',\n",
       " 'tvec__lowercase': True,\n",
       " 'tvec__max_df': 1.0,\n",
       " 'tvec__max_features': None,\n",
       " 'tvec__min_df': 1,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__norm': 'l2',\n",
       " 'tvec__preprocessor': None,\n",
       " 'tvec__smooth_idf': True,\n",
       " 'tvec__stop_words': None,\n",
       " 'tvec__strip_accents': None,\n",
       " 'tvec__sublinear_tf': False,\n",
       " 'tvec__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tvec__tokenizer': None,\n",
       " 'tvec__use_idf': True,\n",
       " 'tvec__vocabulary': None,\n",
       " 'gb__ccp_alpha': 0.0,\n",
       " 'gb__criterion': 'friedman_mse',\n",
       " 'gb__init': None,\n",
       " 'gb__learning_rate': 0.1,\n",
       " 'gb__loss': 'deviance',\n",
       " 'gb__max_depth': 3,\n",
       " 'gb__max_features': None,\n",
       " 'gb__max_leaf_nodes': None,\n",
       " 'gb__min_impurity_decrease': 0.0,\n",
       " 'gb__min_samples_leaf': 1,\n",
       " 'gb__min_samples_split': 2,\n",
       " 'gb__min_weight_fraction_leaf': 0.0,\n",
       " 'gb__n_estimators': 100,\n",
       " 'gb__n_iter_no_change': None,\n",
       " 'gb__random_state': 111,\n",
       " 'gb__subsample': 1.0,\n",
       " 'gb__tol': 0.0001,\n",
       " 'gb__validation_fraction': 0.1,\n",
       " 'gb__verbose': 0,\n",
       " 'gb__warm_start': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get pipeline params\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f756c961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pipeline params by cvec\n",
    "pipe_params = {\n",
    "    \"tvec__tokenizer\": [None, stem_words],\n",
    "    \"tvec__max_features\": [5_000, 10_000, 20_000, 30_000],\n",
    "    \"tvec__min_df\": [2, 3],\n",
    "    \"tvec__max_df\": [.9, .95],\n",
    "    \"tvec__stop_words\": [None, \"english\"],\n",
    "    \"tvec__ngram_range\": [(1, 1), (1, 2)],\n",
    "    \"gb__learning_rate\": [0.1, 1, 10],\n",
    "    \"gb__max_depth\": [None, 1, 2, 3, 4],\n",
    "    \"gb__n_estimators\": [100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8f68aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the result of the model with defined parameters in GreadSearch\n",
    "gridsearching(estimator=pipe, param_grid=pipe_params, model_name=\"GradientBoost\", transformer_name=\"TfidfVectorizer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
