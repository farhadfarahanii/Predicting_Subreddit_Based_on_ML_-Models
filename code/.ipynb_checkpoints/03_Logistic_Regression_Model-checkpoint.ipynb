{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aece2e75",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054d237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc067be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataframe path\n",
    "df_path = \"../data/final_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d95d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(df_path).drop(columns=\"Unnamed: 0\")\n",
    "\n",
    "# Get some basic information \n",
    "print(f\"Sample Data :{df.head()}\")\n",
    "print(f\"\\n--------------------------\\n\\n Columns : {[i for i in df.columns]}\")\n",
    "print(f\"\\n--------------------------\\n\\n Size of the dataset : {df.shape[0]}\")\n",
    "print(f\"\\n--------------------------\\n\\n Total number of columns : {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093122c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unusefull columns\n",
    "df.drop(columns =[\"author\", \"des_word_count\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a08fa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label column (target column)\n",
    "df[\"subreddit\"] = df[\"subreddit\"].map({\"GalaxyWatch\": 1, \"AppleWatch\":0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89025781",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8636a2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cite: Got help form Katie Sylvia\n",
    "# a function for stemming\n",
    "def stem_words(text):\n",
    "    # Initialize the Porter stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    # Tokenize the text into individual words\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Stem each word and join them back into a string\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    stemmed_text = \" \".join(stemmed_words)\n",
    "    \n",
    "    return stemmed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3645e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search over with pipeline estimator\n",
    "def gridsearching(estimator, param_grid, model_name, transformer_name):\n",
    "    \n",
    "    print(f\" Summary of {model_name} Model with {transformer_name} Transformer Evaluation \".center(115, \"=\"))\n",
    "    \n",
    "    # Instantiate a GridSearch model\n",
    "    gs = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=5, n_jobs=5)\n",
    "\n",
    "    # Fit the model to traning data\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    # Get to know wich params were the best ones\n",
    "    print(\" The Best Params \".center(34, \"=\"))\n",
    "    print(gs.best_params_)\n",
    "    print()\n",
    "\n",
    "    # Get to know the best score\n",
    "    print(\" The Best Score \".center(34, \"=\"))\n",
    "    print(gs.best_score_)\n",
    "    print()\n",
    "\n",
    "    # Train data score\n",
    "    print(\" Train Score \".center(34, \"=\"))\n",
    "    print(gs.score(X_train, y_train))\n",
    "    print()\n",
    "\n",
    "    # Test data score\n",
    "    print(\" Test Score \".center(34, \"=\"))\n",
    "    print(gs.score(X_test, y_test))\n",
    "    \n",
    "    # Get predictions\n",
    "    preds = gs.predict(X_test)\n",
    "\n",
    "    # Confusion matrix values\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "    # Confusion matrix\n",
    "    plot_confusion_matrix(gs, X_test, y_test, cmap=\"Purples\", values_format=\"d\")\n",
    "\n",
    "    plt.title(f\"The Confusion Matrix of {model_name} with {transformer_name}\");\n",
    "\n",
    "    # Evaluate a model\n",
    "    print(f\" Evaluation Metrics \".center(34, \"=\"))\n",
    "    print(f\"Accuracy  ---------- {accuracy_score(y_test, preds)}\")\n",
    "    print(f\"Precision  --------- {precision_score(y_test, preds)}\")\n",
    "    print(f\"Sensitivity  ------- {recall_score(y_test, preds)}\")\n",
    "    print(f\"Specifity  --------- {tn/(tn + fp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb92f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cite: Got that function from GA 603-lesson_random_forest (Katie Sylvia)\n",
    "def plot_feature_importance(importance, names, model_type):\n",
    "\n",
    "\n",
    "    # Create a DataFrame using a Dictionary\n",
    "    df = pd.DataFrame({\"feature_names\":names,\n",
    "                       \"feature_importance\":importance})\n",
    "\n",
    "    # Sort the DataFrame in order decreasing feature importance\n",
    "    df.sort_values(by=[\"feature_importance\"], ascending=False,inplace=True)\n",
    "    top_features = df.head(20)\n",
    "\n",
    "    # Define size of bar plot\n",
    "    plt.figure(figsize=(10,8))\n",
    "    \n",
    "    # Generate a color palette based on the volume of feature importances\n",
    "    palette = sns.color_palette(\"Purples\", len(top_features))\n",
    "    \n",
    "    # Reverse the color palette\n",
    "    reversed_palette = palette[::-1]\n",
    "    \n",
    "    # Plot Searborn bar chart\n",
    "    sns.barplot(x=top_features[\"feature_importance\"], y=top_features[\"feature_names\"], palette=reversed_palette)\n",
    "    \n",
    "    # Add chart labels\n",
    "    plt.title(model_type +  \" Feature Importance\", fontsize=14)\n",
    "    plt.xlabel(\"Feature Importance\", fontsize=12)\n",
    "    plt.ylabel(\"Feature Names\", fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5e41c0",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ae8753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X (features) and y(target)\n",
    "X = df[\"description\"]\n",
    "y = df[\"subreddit\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "print(f\"X shape ---------- {X.shape}\")\n",
    "print(f\"y shape ---------- {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4ee4a6",
   "metadata": {},
   "source": [
    "### Baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6572c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ratio of classes\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4133dd82",
   "metadata": {},
   "source": [
    "**Baseline accuracy score is 0.53 which is the majority class**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867fb8d1",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17b1b05",
   "metadata": {},
   "source": [
    "### Logistic Regression with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58504ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the pipeline with Logistic Regression and CountVectorizer transformer\n",
    "pipe = Pipeline([\n",
    "    (\"cvec\", CountVectorizer()),\n",
    "    (\"lr\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad21d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pipeline params\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fda2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pipeline params by cvec\n",
    "pipe_params = {\n",
    "    \"cvec__tokenizer\": [None, stem_words],\n",
    "    \"cvec__max_features\": [5_000, 10_000, 20_000, 30_000],\n",
    "    \"cvec__min_df\": [2, 3],\n",
    "    \"cvec__max_df\": [.9, .95],\n",
    "    \"cvec__stop_words\": [None, \"english\"],\n",
    "    \"cvec__ngram_range\": [(1, 1), (1, 2)],\n",
    "    \"lr__penalty\": [\"l1\", \"l2\"],\n",
    "    \"lr__C\": np.logspace(-3, 0, 1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34831394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the result of the model with defined parameters in GreadSearch\n",
    "gridsearching(estimator=pipe, param_grid=pipe_params, model_name=\"Logistic Regression\", transformer_name=\"CountVectorizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39652102",
   "metadata": {},
   "source": [
    "### Logistic Regression with TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b0e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the pipeline with Logistic Regression and CountVectorizer transformer\n",
    "pipe = Pipeline([\n",
    "    (\"tvec\", TfidfVectorizer()),\n",
    "    (\"lr\", LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b6d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pipeline params\n",
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d180b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pipeline params by cvec\n",
    "pipe_params = {\n",
    "    \"tvec__tokenizer\": [None, stem_words],\n",
    "    \"tvec__max_features\": [5_000, 10_000, 20_000, 30_000],\n",
    "    \"tvec__min_df\": [2, 3],\n",
    "    \"tvec__max_df\": [.9, .95],\n",
    "    \"tvec__stop_words\": [None, \"english\"],\n",
    "    \"cvec__ngram_range\": [(1, 1), (1, 2)],\n",
    "    \"lr__penalty\": [\"l1\", \"l2\"],\n",
    "    \"lr__C\": np.logspace(-3, 0, 1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b3e0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the result of the model with defined parameters in GreadSearch\n",
    "gridsearching(estimator=pipe, param_grid=pipe_params, model_name=\"Logistic Regression\", transformer_name=\"TfidVectorizer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
