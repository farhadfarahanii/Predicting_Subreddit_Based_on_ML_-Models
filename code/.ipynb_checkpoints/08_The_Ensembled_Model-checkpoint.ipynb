{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0578fdfb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "872f295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, recall_score, precision_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36612f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataframe path\n",
    "df_path = \"../data/final_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15ae715c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data :            author                                        description  \\\n",
      "0          TuaAnon  yes, it's an lte watch with data turned on, no...   \n",
      "1  DemandScary1934  how accurate is the active/total calorie track...   \n",
      "2         Vinumite  fell very hard blackout drunk and lost watch. ...   \n",
      "3          Damarou  pls tell me i‘m not the only one who has such ...   \n",
      "4       ThorNike13  deleted apps in watch app on iphone with weird...   \n",
      "\n",
      "    subreddit  des_word_count  \n",
      "0  AppleWatch              48  \n",
      "1  AppleWatch              10  \n",
      "2  AppleWatch              59  \n",
      "3  AppleWatch              15  \n",
      "4  AppleWatch              15  \n",
      "\n",
      "--------------------------\n",
      "\n",
      " Columns : ['author', 'description', 'subreddit', 'des_word_count']\n",
      "\n",
      "--------------------------\n",
      "\n",
      " Size of the dataset : 5270\n",
      "\n",
      "--------------------------\n",
      "\n",
      " Total number of columns : 4\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv(df_path).drop(columns=\"Unnamed: 0\")\n",
    "\n",
    "# Get some basic information \n",
    "print(f\"Sample Data :{df.head()}\")\n",
    "print(f\"\\n--------------------------\\n\\n Columns : {[i for i in df.columns]}\")\n",
    "print(f\"\\n--------------------------\\n\\n Size of the dataset : {df.shape[0]}\")\n",
    "print(f\"\\n--------------------------\\n\\n Total number of columns : {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0f344b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unusefull columns\n",
    "df.drop(columns =[\"author\", \"des_word_count\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96b24f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label column (target column)\n",
    "df[\"subreddit\"] = df[\"subreddit\"].map({\"GalaxyWatch\": 1, \"AppleWatch\":0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b5d410",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e7135cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cite: Got help form Katie Sylvia\n",
    "# a function for stemming\n",
    "def stem_words(text):\n",
    "    # Initialize the Porter stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    # Tokenize the text into individual words\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Stem each word and join them back into a string\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    stemmed_text = \" \".join(stemmed_words)\n",
    "    \n",
    "    return stemmed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f93e176",
   "metadata": {},
   "source": [
    "## Baselin Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca03e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape ---------- (5270,)\n",
      "y shape ---------- (5270,)\n"
     ]
    }
   ],
   "source": [
    "# Define X (features) and y(target)\n",
    "X = df[\"description\"]\n",
    "y = df[\"subreddit\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "print(f\"X shape ---------- {X.shape}\")\n",
    "print(f\"y shape ---------- {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c97335b",
   "metadata": {},
   "source": [
    "### Baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a33febb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.534143\n",
       "1    0.465857\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the ratio of classes\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa98b3b",
   "metadata": {},
   "source": [
    "## Review The Models Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67e0a9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the pipelines (without Bagged Decision Tree and AdaBoost because of their poor\n",
    "# performance comparing to their modelling groups)\n",
    "# Logistic Regression pipeline\n",
    "pipe_lr = Pipeline([\n",
    "    (\"cvec\", CountVectorizer()), # The model performed better with CountVectorizer\n",
    "    (\"lr\", LogisticRegression())\n",
    "])\n",
    "\n",
    "# Multinomial Naïve Bayes pipeline\n",
    "pipe_nb = Pipeline([\n",
    "    (\"cvec\", CountVectorizer()), # The model performed better with CountVectorizer\n",
    "    (\"nb\", MultinomialNB())\n",
    "])\n",
    "\n",
    "# Random Forest pipeline\n",
    "pipe_rf = Pipeline([\n",
    "    (\"tvec\", TfidfVectorizer()), # The model performed better with TfidfVectorizer\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Extra Trees pipeline\n",
    "pipe_et = Pipeline([\n",
    "    (\"tvec\", TfidfVectorizer()), # The model performed better with TfidfVectorizer\n",
    "    (\"et\", ExtraTreesClassifier())\n",
    "])\n",
    "\n",
    "# Gradient Boost pipeline\n",
    "pipe_gb = Pipeline([\n",
    "    (\"cvec\", CountVectorizer()), # The model performed better with CountVectorizer\n",
    "    (\"gb\", GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "# XGBoost pipeline\n",
    "pipe_xgb = Pipeline([\n",
    "    (\"cvec\", CountVectorizer()), # The model performed better with CountVectorizer\n",
    "    (\"xgb\", xgb.XGBClassifier())\n",
    "])\n",
    "\n",
    "# SVM pipeline\n",
    "pipe_svc = Pipeline([\n",
    "    (\"tvec\", TfidfVectorizer()), # The model performed better with TfidfVectorizer\n",
    "    (\"svc\", SVC())\n",
    "])\n",
    "\n",
    "# Make a list of pipelines\n",
    "pipelines = [pipe_lr, pipe_nb, pipe_rf, pipe_et, pipe_gb, pipe_xgb, pipe_svc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c096bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffb46a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
