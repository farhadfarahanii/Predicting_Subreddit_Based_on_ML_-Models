{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0578fdfb",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "872f295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36612f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataframe path\n",
    "df_path = \"../data/final_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15ae715c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data :            author                                        description  \\\n",
      "0          TuaAnon  yes, it's an lte watch with data turned on, no...   \n",
      "1  DemandScary1934  how accurate is the active/total calorie track...   \n",
      "2         Vinumite  fell very hard blackout drunk and lost watch. ...   \n",
      "3          Damarou  pls tell me i‘m not the only one who has such ...   \n",
      "4       ThorNike13  deleted apps in watch app on iphone with weird...   \n",
      "\n",
      "    subreddit  des_word_count  \n",
      "0  AppleWatch              48  \n",
      "1  AppleWatch              10  \n",
      "2  AppleWatch              59  \n",
      "3  AppleWatch              15  \n",
      "4  AppleWatch              15  \n",
      "\n",
      "--------------------------\n",
      "\n",
      " Columns : ['author', 'description', 'subreddit', 'des_word_count']\n",
      "\n",
      "--------------------------\n",
      "\n",
      " Size of the dataset : 5270\n",
      "\n",
      "--------------------------\n",
      "\n",
      " Total number of columns : 4\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv(df_path).drop(columns=\"Unnamed: 0\")\n",
    "\n",
    "# Get some basic information \n",
    "print(f\"Sample Data :{df.head()}\")\n",
    "print(f\"\\n--------------------------\\n\\n Columns : {[i for i in df.columns]}\")\n",
    "print(f\"\\n--------------------------\\n\\n Size of the dataset : {df.shape[0]}\")\n",
    "print(f\"\\n--------------------------\\n\\n Total number of columns : {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0f344b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unusefull columns\n",
    "df.drop(columns =[\"author\", \"des_word_count\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96b24f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label column (target column)\n",
    "df[\"subreddit\"] = df[\"subreddit\"].map({\"GalaxyWatch\": 1, \"AppleWatch\":0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b5d410",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e7135cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cite: Got help form Katie Sylvia\n",
    "# a function for stemming\n",
    "def stem_words(text):\n",
    "    # Initialize the Porter stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    # Tokenize the text into individual words\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Stem each word and join them back into a string\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    stemmed_text = \" \".join(stemmed_words)\n",
    "    \n",
    "    return stemmed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f93e176",
   "metadata": {},
   "source": [
    "## Baselin Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ca03e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape ---------- (5270,)\n",
      "y shape ---------- (5270,)\n"
     ]
    }
   ],
   "source": [
    "# Define X (features) and y(target)\n",
    "X = df[\"description\"]\n",
    "y = df[\"subreddit\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "print(f\"X shape ---------- {X.shape}\")\n",
    "print(f\"y shape ---------- {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c97335b",
   "metadata": {},
   "source": [
    "### Baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a33febb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.534143\n",
       "1    0.465857\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the ratio of classes\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa98b3b",
   "metadata": {},
   "source": [
    "## Review The Models Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67e0a9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the pipelines (without Bagged Decision Tree and AdaBoost because of their poor\n",
    "# performance comparing to their modelling groups)\n",
    "# Logistic Regression pipeline\n",
    "pipe_lr = Pipeline([\n",
    "    (\"tvec\", TfidfVectorizer()), # The model performed better with TfidfVectorizer\n",
    "    (\"lr\", LogisticRegression(solver=\"saga\"))\n",
    "])\n",
    "\n",
    "# Multinomial Naïve Bayes pipeline\n",
    "pipe_nb = Pipeline([\n",
    "    (\"cvec\", CountVectorizer()), # The model performed better with CountVectorizer\n",
    "    (\"nb\", MultinomialNB())\n",
    "])\n",
    "\n",
    "# Random Forest pipeline\n",
    "pipe_rf = Pipeline([\n",
    "    (\"tvec\", TfidfVectorizer()), # The model performed better with TfidfVectorizer\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Extra Trees pipeline\n",
    "pipe_et = Pipeline([\n",
    "    (\"tvec\", TfidfVectorizer()), # The model performed better with TfidfVectorizer\n",
    "    (\"et\", ExtraTreesClassifier())\n",
    "])\n",
    "\n",
    "# Gradient Boost pipeline\n",
    "pipe_gb = Pipeline([\n",
    "    (\"cvec\", CountVectorizer()), # The model performed better with CountVectorizer\n",
    "    (\"gb\", GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "# XGBoost pipeline\n",
    "pipe_xgb = Pipeline([\n",
    "    (\"cvec\", CountVectorizer()), # The model performed better with CountVectorizer\n",
    "    (\"xgb\", xgb.XGBClassifier())\n",
    "])\n",
    "\n",
    "# SVM pipeline\n",
    "pipe_svc = Pipeline([\n",
    "    (\"tvec\", TfidfVectorizer()), # The model performed better with TfidfVectorizer\n",
    "    (\"svc\", SVC())\n",
    "])\n",
    "\n",
    "# Make a list of pipelines\n",
    "pipelines = [pipe_lr, pipe_nb, pipe_rf, pipe_et, pipe_gb, pipe_xgb, pipe_svc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06c096bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for each pipe\n",
    "\n",
    "param_lr = {'lr__C': [100],                     # [0.1, 1, 10, 100] tested and 100 was chosen as the best param\n",
    "            'lr__penalty': ['l1'],              # [\"none\", \"l1\", \"l2\"] tested and l1 was chosen as the best param\n",
    "            'tvec__max_df': [0.95],             # [.9, .95] tested and 0.95 was chosen as the best param\n",
    "            'tvec__max_features': [20000],      # [5_000, 10_000, 20_000, 30_000] tested and 20000 was chosen as the best param\n",
    "            'tvec__min_df': [2],                # [2, 3] tested and 2 was chosen as the best param\n",
    "            'tvec__ngram_range': [(1, 2)],      # [(1, 1), (1, 2)] tested and (1, 2) was chosen as the best param\n",
    "            'tvec__stop_words': [None],         # [None, \"english\"] tested and None was chosen as the best param\n",
    "            'tvec__tokenizer': [None]}          # [None, stem_words] tested and None was chosen as the best param\n",
    "\n",
    "param_nb = {'cvec__max_df': [0.9],              # [.9, .95] tested and 0.9 was chosen as the best param\n",
    "            'cvec__max_features': [10000],      # [5_000, 10_000, 20_000, 30_000] tested and 10000 was chosen as the best param\n",
    "            'cvec__min_df': [2],                # [2, 3] tested and 2 was chosen as the best param\n",
    "            'cvec__ngram_range': [(1, 2)],      # [(1, 1), (1, 2)] tested and (1, 2) was chosen as the best param\n",
    "            'cvec__stop_words': ['english'],    # [None, \"english\"] tested and 'english' was chosen as the best param\n",
    "            'cvec__tokenizer': [None]}          # [None, stem_words] tested and None was chosen as the best param\n",
    "\n",
    "param_rf = {'rf__max_depth': [None],            # [None, 1, 2, 3, 4] tested and None was chosen as the best param\n",
    "            'rf__n_estimators': [100],          # The only estimator\n",
    "            'tvec__max_df': [0.95],             # [.9, .95] tested and 0.95 was chosen as the best param\n",
    "            'tvec__max_features': [30000],      # [5_000, 10_000, 20_000, 30_000] tested and 30000 was chosen as the best param \n",
    "            'tvec__min_df': [2],                # [2, 3] tested and 2 was chosen as the best param\n",
    "            'tvec__ngram_range': [(1, 1)],      # [(1, 1), (1, 2)] tested and (1, 1) was chosen as the best param\n",
    "            'tvec__stop_words': ['english'],    # [None, \"english\"] tested and 'english' was chosen as the best param\n",
    "            'tvec__tokenizer': [None]}          # [None, stem_words] tested and None was chosen as the best param\n",
    "\n",
    "param_et = {'et__max_depth': [None],            # [None, 1, 2, 3, 4] tested and None was chosen as the best param\n",
    "            'et__n_estimators': [100],          # The only estimator\n",
    "            'tvec__max_df': [0.95],             # [.9, .95] tested and 0.95 was chosen as the best param\n",
    "            'tvec__max_features': [30000],      # [5_000, 10_000, 20_000, 30_000] tested and 30000 was chosen as the best param \n",
    "            'tvec__min_df': [2],                # [2, 3] tested and 2 was chosen as the best param\n",
    "            'tvec__ngram_range': [(1, 1)],      # [(1, 1), (1, 2)] tested and (1, 1) was chosen as the best param\n",
    "            'tvec__stop_words': ['english'],    # [None, \"english\"] tested and 'english' was chosen as the best param\n",
    "            'tvec__tokenizer': [None]}          # [None, stem_words] tested and None was chosen as the best param\n",
    "\n",
    "param_gb = {'cvec__max_df': [0.9],              # [.9, .95] tested and 0.9 was chosen as the best param\n",
    "            'cvec__max_features': [5000],       # [5_000, 10_000, 20_000, 30_000] tested and 5000 was chosen as the best param \n",
    "            'cvec__min_df': [2],                # [2, 3] tested and 2 was chosen as the best param\n",
    "            'cvec__ngram_range': [(1, 2)],      # [(1, 1), (1, 2)] tested and (1, 2) was chosen as the best param\n",
    "            'cvec__stop_words': [None],         # [None, \"english\"] tested and None was chosen as the best param\n",
    "            'cvec__tokenizer': [stem_words],    # [None, stem_words] tested and stem_words was chosen as the best param\n",
    "            'gb__learning_rate': [0.1],         # [0.1, 1, 10] tested and 0.1 was chosen as the best param\n",
    "            'gb__max_depth': [3],               # [None, 1, 2, 3, 4] tested and 3 was chosen as the best param\n",
    "            'gb__n_estimators': [100]}          # The only estimator\n",
    "\n",
    "param_xgb = {'cvec__max_df': [0.9],             # [.9, .95] tested and 0.9 was chosen as the best param\n",
    "            'cvec__max_features': [5000],       # [5_000, 10_000, 20_000, 30_000] tested and 5000 was chosen as the best param \n",
    "            'cvec__min_df': [2],                # [2, 3] tested and 2 was chosen as the best param\n",
    "            'cvec__ngram_range': [(1, 2)],      # [(1, 1), (1, 2)] tested and (1, 2) was chosen as the best param\n",
    "            'cvec__stop_words': ['english'],    # [None, \"english\"] tested and 'english' was chosen as the best param\n",
    "            'cvec__tokenizer': [stem_words],    # [None, stem_words] tested and stem_words was chosen as the best param\n",
    "            'xgb__learning_rate': [0.1],        # [0.1, 1, 10] tested and 0.1 was chosen as the best param\n",
    "            'xgb__max_depth': [4],              # [None, 1, 2, 3, 4] tested and 4 was chosen as the best param\n",
    "            'xgb__n_estimators': [100]}         # The only estimator\n",
    "\n",
    "param_svc = {'svc__C': [100],                   # [0.1, 1, 10, 100] tested and 100 was chosen as the best param\n",
    "            'svc__kernel': ['rbf'],             # 'rbf' and 'poly' (with \"degree\": [2, 3, 4]) tested and 'rbf' was chosen as the best param\n",
    "            'tvec__max_df': [0.9],              # [.9, .95] tested and 0.95 was chosen as the best param\n",
    "            'tvec__max_features': [20000],      # [5_000, 10_000, 20_000, 30_000] tested and 30000 was chosen as the best param \n",
    "            'tvec__min_df': [2],                # [2, 3] tested and 2 was chosen as the best param\n",
    "            'tvec__ngram_range': [(1, 2)],      # [(1, 1), (1, 2)] tested and (1, 1) was chosen as the best param\n",
    "            'tvec__stop_words': [None],         # [None, \"english\"] tested and 'english' was chosen as the best param\n",
    "            'tvec__tokenizer': [None]}          # [None, stem_words] tested and None was chosen as the best param\n",
    "\n",
    "# Make a list of pipes params\n",
    "pipe_prarams = [param_lr, param_nb, param_rf, param_et, param_gb, param_xgb, param_svc]\n",
    "\n",
    "# Make a list of models names\n",
    "names = [\"Logistic Regression Model\", \"Naïve Bayes Model\", \"Random Forest Model\",\n",
    "         \"Extra Trees\", \"Gradient Boost\", \"XGBoost Model\", \"SVM Model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ffb46a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarvin.farhad\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression Model ====\n",
      "Accuracy  ---------- 0.8960546282245827\n",
      "Precision  --------- 0.8929159802306426\n",
      "Sensitivity  ------- 0.8827361563517915\n",
      "Specifity  --------- 0.9076704545454546\n",
      "F1 Score ----------- 0.8877968877968878\n",
      "\n",
      "======= Naïve Bayes Model ========\n",
      "Accuracy  ---------- 0.9066767830045523\n",
      "Precision  --------- 0.8966074313408724\n",
      "Sensitivity  ------- 0.9039087947882736\n",
      "Specifity  --------- 0.9090909090909091\n",
      "F1 Score ----------- 0.900243309002433\n",
      "\n",
      "====== Random Forest Model =======\n",
      "Accuracy  ---------- 0.8952959028831563\n",
      "Precision  --------- 0.9146341463414634\n",
      "Sensitivity  ------- 0.8550488599348535\n",
      "Specifity  --------- 0.9303977272727273\n",
      "F1 Score ----------- 0.8838383838383839\n",
      "\n",
      "========== Extra Trees ===========\n",
      "Accuracy  ---------- 0.8998482549317147\n",
      "Precision  --------- 0.9126712328767124\n",
      "Sensitivity  ------- 0.8680781758957655\n",
      "Specifity  --------- 0.9275568181818182\n",
      "F1 Score ----------- 0.8898163606010018\n",
      "\n",
      "========= Gradient Boost =========\n",
      "Accuracy  ---------- 0.8983308042488619\n",
      "Precision  --------- 0.9166666666666666\n",
      "Sensitivity  ------- 0.8599348534201955\n",
      "Specifity  --------- 0.9318181818181818\n",
      "F1 Score ----------- 0.8873949579831933\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarvin.farhad\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [' ', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= XGBoost Model ==========\n",
      "Accuracy  ---------- 0.8930197268588771\n",
      "Precision  --------- 0.9042735042735043\n",
      "Sensitivity  ------- 0.8615635179153095\n",
      "Specifity  --------- 0.9204545454545454\n",
      "F1 Score ----------- 0.8824020016680567\n",
      "\n",
      "=========== SVM Model ============\n",
      "Accuracy  ---------- 0.9013657056145675\n",
      "Precision  --------- 0.9172413793103448\n",
      "Sensitivity  ------- 0.8664495114006515\n",
      "Specifity  --------- 0.9318181818181818\n",
      "F1 Score ----------- 0.8911222780569514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pipe, pgrid, name in zip(pipelines, pipe_prarams, names):\n",
    "    \n",
    "    # Instantiate Gread Search\n",
    "    gs = GridSearchCV(estimator=pipe, param_grid=pgrid, cv=5, n_jobs=4)\n",
    "    \n",
    "    # Fit the model\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict y\n",
    "    preds = gs.predict(X_test)\n",
    "    \n",
    "    # Confusion matrix values\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "    \n",
    "    # Define the path where model should be saved\n",
    "    model_path = f\"../models/{name}.pkl\"\n",
    "    \n",
    "    # Save the model\n",
    "    with open(model_path, \"wb\") as pickle_out:\n",
    "        pickle_out = pickle.dump(gs, pickle_out)\n",
    "        \n",
    "    # Evaluate the model\n",
    "    print(f\" {name} \".center(34, \"=\"))\n",
    "    print(f\"Accuracy  ---------- {accuracy_score(y_test, preds)}\")\n",
    "    print(f\"Precision  --------- {precision_score(y_test, preds)}\")\n",
    "    print(f\"Sensitivity  ------- {recall_score(y_test, preds)}\")\n",
    "    print(f\"Specifity  --------- {tn/(tn + fp)}\")\n",
    "    print(f\"F1 Score ----------- {f1_score(y_test, preds)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc08481f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
